{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RECAST3D REConstruction of Arbitrary Slices in Tomography This project contains a full-stack implementation of a tomographic reconstruction and visualization pipeline. RECAST3D is visualization software for tomographic imaging based on on-demand reconstruction of arbitrary slices, and is built for use in a distributed, real-time, and online reconstruction pipeline. The repository also contains two support libraries, TomoPackets and SliceRecon . The TomoPackets library defines a protocol for sending messages between the different components (scanners, reconstruction nodes, visualization workstations) for real-time tomographic reconstruction and we encourage its use also outside of RECAST3D. SliceRecon contains efficient implementations for reconstructing arbitrarily oriented slices through a 3D volume. It defines servers that are able to communicate to data sources (using TomoPackets) and visualization software (such as, but not exclusively, RECAST3D). Installation For installation instructions, see the installation documentation . Authors RECAST3D is developed by the Computational Imaging group at CWI. Original author: Jan-Willem Buurlage (@jwbuurlage) Contributions by: Holger Kohr (@kohr-h) Willem Jan Palenstijn (@wjp) Allard Hendriksen (@ahendriksen) Adriaan Graas (@adriaangraas) Daan Pelt (@dmpelt) Contributing We welcome contributions. Please submit pull requests against the develop branch. If you have any issues, questions, or remarks, then please open an issue on GitHub. Publications using RECAST3D Article Code Real-time reconstruction and visualisation \u2026 at TOMCAT . Sci.Rep. DOI Real-time quasi-3D tomographic reconstruction . MST. DOI Please cite us If you have used RECAST3D for a scientific publication, we would appreciate citations to the following paper: Real-time quasi-3D tomographic reconstruction. JW Buurlage, H Kohr, WJ Palenstijn, KJ Batenburg. Measurement Science and Technology (2018) License This project is licensed under the GPL. See LICENSE.md for details.","title":"Home"},{"location":"#recast3d","text":"REConstruction of Arbitrary Slices in Tomography This project contains a full-stack implementation of a tomographic reconstruction and visualization pipeline. RECAST3D is visualization software for tomographic imaging based on on-demand reconstruction of arbitrary slices, and is built for use in a distributed, real-time, and online reconstruction pipeline. The repository also contains two support libraries, TomoPackets and SliceRecon . The TomoPackets library defines a protocol for sending messages between the different components (scanners, reconstruction nodes, visualization workstations) for real-time tomographic reconstruction and we encourage its use also outside of RECAST3D. SliceRecon contains efficient implementations for reconstructing arbitrarily oriented slices through a 3D volume. It defines servers that are able to communicate to data sources (using TomoPackets) and visualization software (such as, but not exclusively, RECAST3D).","title":"RECAST3D"},{"location":"#installation","text":"For installation instructions, see the installation documentation .","title":"Installation"},{"location":"#authors","text":"RECAST3D is developed by the Computational Imaging group at CWI. Original author: Jan-Willem Buurlage (@jwbuurlage) Contributions by: Holger Kohr (@kohr-h) Willem Jan Palenstijn (@wjp) Allard Hendriksen (@ahendriksen) Adriaan Graas (@adriaangraas) Daan Pelt (@dmpelt)","title":"Authors"},{"location":"#contributing","text":"We welcome contributions. Please submit pull requests against the develop branch. If you have any issues, questions, or remarks, then please open an issue on GitHub.","title":"Contributing"},{"location":"#publications-using-recast3d","text":"Article Code Real-time reconstruction and visualisation \u2026 at TOMCAT . Sci.Rep. DOI Real-time quasi-3D tomographic reconstruction . MST. DOI","title":"Publications using RECAST3D"},{"location":"#please-cite-us","text":"If you have used RECAST3D for a scientific publication, we would appreciate citations to the following paper: Real-time quasi-3D tomographic reconstruction. JW Buurlage, H Kohr, WJ Palenstijn, KJ Batenburg. Measurement Science and Technology (2018)","title":"Please cite us"},{"location":"#license","text":"This project is licensed under the GPL. See LICENSE.md for details.","title":"License"},{"location":"changelog/","text":"Changelog All notable changes to the RECAST3D stack will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . Unreleased Added RECAST3D Add support for trackers, benchmarks, and parameter control for upstream components Add experimental transparent reconstruction mode (this makes air on slices see-through) Add feature to set permanently fixed slices for analysis with middle mouse button TomoPackets Add re-export of scan_settings_packet to the tomop Python library. Add named arguments to tomop class constructors. Add already_linear flag to ScanSettingsPacket . Add Parameter{Bool,Float,Enum}Packet , TrackerPacket and BenchmarkPacket . Add support for std::vector<std::string> fields. SliceRecon Add continuous flag, for reconstructions happening more often than one rotation (#4). Add already_linear flag, for already linearized data. Add support for skipping flat fielding step. Add Gaussian filter for optional noise suppression Add support for Paganin filtering Add support for manually choosing tilt axis for parallel beam geometries Add bench flag for (optional) benchmarking support Fixed RECAST3D Fix scaling of 3D volume preview in reconstruction SliceRecon Fix application of FDK weighting. Fix possible simultaneous access to a plugin socket Fix uploads not triggering when group_size did not divide proj_count (#9) Change plugin::listen to run on the main thread Change default value for flat field to 1 , darks and flats are now optional (#6). Use FFTW3 as the FFT backend (instead of an unsupported Eigen module). More modular system for processing projections Changed RECAST3D Initial scaling is now based on first received nonzero data 1.0.0-rc.1 - 2018-11-13 Added Add documentation Improved build scripts Use TomoPackets v1.0.0 Removed Disable 2D scenes Disable movie scenes Disable dataset loading 0.1.0 - 2018-06-21 Initial release.","title":"Release Notes"},{"location":"changelog/#changelog","text":"All notable changes to the RECAST3D stack will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"Unreleased"},{"location":"changelog/#added","text":"","title":"Added"},{"location":"changelog/#recast3d","text":"Add support for trackers, benchmarks, and parameter control for upstream components Add experimental transparent reconstruction mode (this makes air on slices see-through) Add feature to set permanently fixed slices for analysis with middle mouse button","title":"RECAST3D"},{"location":"changelog/#tomopackets","text":"Add re-export of scan_settings_packet to the tomop Python library. Add named arguments to tomop class constructors. Add already_linear flag to ScanSettingsPacket . Add Parameter{Bool,Float,Enum}Packet , TrackerPacket and BenchmarkPacket . Add support for std::vector<std::string> fields.","title":"TomoPackets"},{"location":"changelog/#slicerecon","text":"Add continuous flag, for reconstructions happening more often than one rotation (#4). Add already_linear flag, for already linearized data. Add support for skipping flat fielding step. Add Gaussian filter for optional noise suppression Add support for Paganin filtering Add support for manually choosing tilt axis for parallel beam geometries Add bench flag for (optional) benchmarking support","title":"SliceRecon"},{"location":"changelog/#fixed","text":"","title":"Fixed"},{"location":"changelog/#recast3d_1","text":"Fix scaling of 3D volume preview in reconstruction","title":"RECAST3D"},{"location":"changelog/#slicerecon_1","text":"Fix application of FDK weighting. Fix possible simultaneous access to a plugin socket Fix uploads not triggering when group_size did not divide proj_count (#9) Change plugin::listen to run on the main thread Change default value for flat field to 1 , darks and flats are now optional (#6). Use FFTW3 as the FFT backend (instead of an unsupported Eigen module). More modular system for processing projections","title":"SliceRecon"},{"location":"changelog/#changed","text":"","title":"Changed"},{"location":"changelog/#recast3d_2","text":"Initial scaling is now based on first received nonzero data","title":"RECAST3D"},{"location":"changelog/#100-rc1-2018-11-13","text":"","title":"1.0.0-rc.1 - 2018-11-13"},{"location":"changelog/#added_1","text":"Add documentation Improved build scripts Use TomoPackets v1.0.0","title":"Added"},{"location":"changelog/#removed","text":"Disable 2D scenes Disable movie scenes Disable dataset loading","title":"Removed"},{"location":"changelog/#010-2018-06-21","text":"Initial release.","title":"0.1.0 - 2018-06-21"},{"location":"installation_instructions/","text":"Installation The CI CWI group develops a set of libraries and software for real-time tomographic reconstruction. The main software packages are: RECAST3D . The visualization software. This typically runs at a workstation, and is controlled by a user looking at live reconstructions of arbitrarily oriented slices. SliceRecon . The reconstruction software library. This runs on a computer with a GPU (it can be the same as the workstation running RECAST3D). It receives the projection data, and performs slice reconstructions. TomoPackets . The glue between the different components. This library defines a protocol for sending messages between scanners, reconstruction nodes, and visualization workstations. Depending on the data source, an adapter is needed that converts the acquisition metadata and projection data into a common format defined by TomoPackets. This common format that is used as input to SliceRecon. (Recommended) Installation using Conda The RECAST3D reconstruction stack can be installed using: conda install -c cicwi recast3d tomopackets slicerecon Example scripts such as adapters and plugins, can be found in the GitHub repository . To test the installation, follow running the stack . Info The software is developed for Linux. SliceRecon requires a CUDA capable GPU. (Advanced) Manual installation Here, we will describe in detail how to manually build all the different components of the live reconstruction software stack. Warning If you run into unexpected problems while following this guide, please let us know !. 0. (optional) Setting up a fresh Conda (or VirtualEnv ) environment Although it is not strictly necessary to use any Python component, it is by far the easiest way to extend and customize the software. We would suggest making a new environment in which the Python bindings to our libraries are installed. For example: conda create -n live conda activate live if you choose to do this, make and activate the environment before following the rest of these instructions. 1. Building and installing ASTRA Recommended: Using conda Info Currently (March 2020), the required files are only part of the development package of ASTRA. This can be installed using: conda install -c astra-toolbox/label/dev astra-toolbox Install the ASTRA toolbox into your conda environment using: conda install -c astra-toolbox astra-toolbox ASTRA also includes headers and configuration files as part of its conda package. Alternative: From source Warning The software requires at least version v1.9 of the ASTRA toolbox, available from the ASTRA repository on github . We have to install the ASTRA toolbox . We need ASTRA with CUDA support, and install it in such a way so that pkg-config is able to find the library. See the ASTRA documentation for details on installing ASTRA as a C++ library. Setup pkgconfig The rest of this guide assumes that pkgconfig can find the ASTRA configuration, for this you might have to run something along the lines of: # when installed using conda export PKG_CONFIG_PATH = $CONDA_PREFIX /lib/pkgconfig/: $PKG_CONFIG_PATH # when installed from source export PKG_CONFIG_PATH = $ASTRA_SRC_DIR /build/linux: $PKG_CONFIG_PATH 2. Installing prerequisites Next, make sure you have the necessary OpenGL development headers and libraries and other dependencies installed. This highly depends on your operating system and/or distribution. A non-exhaustive lists of packages that might be required on Fedora 31: dnf install python-devel boost-devel libXinerama-devel fftw-devel dnf groupinstall \"X Software Development\" dnf groupinstall \"Development Tools\" Optionally, preinstall the submodule dependencies to speed up the build. For example: dnf install python-devel eigen3-devel boost-devel libXinerama-devel glm-devel If our build script cannot find these dependencies, it will build them from source. 3. Cloning the repository git clone https : //www.github.com/cicwi/RECAST3D recast3d-stack cd recast3d - stack git submodule update -- init -- recursive 4. Building the software TomoPackets cd tomopackets mkdir build && cd build cmake .. && make When developing your own data adapter (or using an existing one), it is easiest to use the Python bindings to the TomoPackets communication library. To install it into your Python environment, run the following: cd .. pip install --user cmake_setuptools pip install -e . You can now develop and run TomoPackets extensions such as data adapters. SliceRecon Next, we install SliceRecon. cd ../slicerecon mkdir build && cd build cmake .. && make This will create a binary slicerecon_server . Next, we install the Python bindings. cd ../python/ pip install -e . RECAST3D To build RECAST3D, run: cd ../../recast3d mkdir build && cd build cmake .. && make This will create a binary recast3d . Test if you can run RECAST3D: ./recast3d This should open an empty white window with a menubar. If you run into any issues, please let us know ! 5. Testing the installation To test if the SliceRecon software is installed correctly, try the following steps. Start up a RECAST3D instance . Change directories to the recast3d/build directory we made before, and run: ./recast3d Start up a SliceRecon server , that connects to RECAST3D and listens for incoming (projection) data. Change directories to slicerecon/build , and run: ./slicerecon_server --slice-size 512 --preview-size 256 Switching windows to the RECAST3D software, you should see a new scene with empty slices. Pushing data into SliceRecon . The server is unable to reconstruct anything interesting, because it has received no data yet. To push some example data into SliceRecon, we run one of the adapter examples. For example, relative to the recast3d_stack directory: cd examples/adapters python zero_adapter.py This will send data containing zeros to the SliceRecon server.","title":"Installation"},{"location":"installation_instructions/#installation","text":"The CI CWI group develops a set of libraries and software for real-time tomographic reconstruction. The main software packages are: RECAST3D . The visualization software. This typically runs at a workstation, and is controlled by a user looking at live reconstructions of arbitrarily oriented slices. SliceRecon . The reconstruction software library. This runs on a computer with a GPU (it can be the same as the workstation running RECAST3D). It receives the projection data, and performs slice reconstructions. TomoPackets . The glue between the different components. This library defines a protocol for sending messages between scanners, reconstruction nodes, and visualization workstations. Depending on the data source, an adapter is needed that converts the acquisition metadata and projection data into a common format defined by TomoPackets. This common format that is used as input to SliceRecon.","title":"Installation"},{"location":"installation_instructions/#recommended-installation-using-conda","text":"The RECAST3D reconstruction stack can be installed using: conda install -c cicwi recast3d tomopackets slicerecon Example scripts such as adapters and plugins, can be found in the GitHub repository . To test the installation, follow running the stack . Info The software is developed for Linux. SliceRecon requires a CUDA capable GPU.","title":"(Recommended) Installation using Conda"},{"location":"installation_instructions/#advanced-manual-installation","text":"Here, we will describe in detail how to manually build all the different components of the live reconstruction software stack. Warning If you run into unexpected problems while following this guide, please let us know !.","title":"(Advanced) Manual installation"},{"location":"installation_instructions/#0-optional-setting-up-a-fresh-conda-or-virtualenv-environment","text":"Although it is not strictly necessary to use any Python component, it is by far the easiest way to extend and customize the software. We would suggest making a new environment in which the Python bindings to our libraries are installed. For example: conda create -n live conda activate live if you choose to do this, make and activate the environment before following the rest of these instructions.","title":"0. (optional) Setting up a fresh Conda (or VirtualEnv) environment"},{"location":"installation_instructions/#1-building-and-installing-astra","text":"","title":"1. Building and installing ASTRA"},{"location":"installation_instructions/#recommended-using-conda","text":"Info Currently (March 2020), the required files are only part of the development package of ASTRA. This can be installed using: conda install -c astra-toolbox/label/dev astra-toolbox Install the ASTRA toolbox into your conda environment using: conda install -c astra-toolbox astra-toolbox ASTRA also includes headers and configuration files as part of its conda package.","title":"Recommended: Using conda"},{"location":"installation_instructions/#alternative-from-source","text":"Warning The software requires at least version v1.9 of the ASTRA toolbox, available from the ASTRA repository on github . We have to install the ASTRA toolbox . We need ASTRA with CUDA support, and install it in such a way so that pkg-config is able to find the library. See the ASTRA documentation for details on installing ASTRA as a C++ library.","title":"Alternative: From source"},{"location":"installation_instructions/#setup-pkgconfig","text":"The rest of this guide assumes that pkgconfig can find the ASTRA configuration, for this you might have to run something along the lines of: # when installed using conda export PKG_CONFIG_PATH = $CONDA_PREFIX /lib/pkgconfig/: $PKG_CONFIG_PATH # when installed from source export PKG_CONFIG_PATH = $ASTRA_SRC_DIR /build/linux: $PKG_CONFIG_PATH","title":"Setup pkgconfig"},{"location":"installation_instructions/#2-installing-prerequisites","text":"Next, make sure you have the necessary OpenGL development headers and libraries and other dependencies installed. This highly depends on your operating system and/or distribution. A non-exhaustive lists of packages that might be required on Fedora 31: dnf install python-devel boost-devel libXinerama-devel fftw-devel dnf groupinstall \"X Software Development\" dnf groupinstall \"Development Tools\" Optionally, preinstall the submodule dependencies to speed up the build. For example: dnf install python-devel eigen3-devel boost-devel libXinerama-devel glm-devel If our build script cannot find these dependencies, it will build them from source.","title":"2. Installing prerequisites"},{"location":"installation_instructions/#3-cloning-the-repository","text":"git clone https : //www.github.com/cicwi/RECAST3D recast3d-stack cd recast3d - stack git submodule update -- init -- recursive","title":"3. Cloning the repository"},{"location":"installation_instructions/#4-building-the-software","text":"","title":"4. Building the software"},{"location":"installation_instructions/#tomopackets","text":"cd tomopackets mkdir build && cd build cmake .. && make When developing your own data adapter (or using an existing one), it is easiest to use the Python bindings to the TomoPackets communication library. To install it into your Python environment, run the following: cd .. pip install --user cmake_setuptools pip install -e . You can now develop and run TomoPackets extensions such as data adapters.","title":"TomoPackets"},{"location":"installation_instructions/#slicerecon","text":"Next, we install SliceRecon. cd ../slicerecon mkdir build && cd build cmake .. && make This will create a binary slicerecon_server . Next, we install the Python bindings. cd ../python/ pip install -e .","title":"SliceRecon"},{"location":"installation_instructions/#recast3d","text":"To build RECAST3D, run: cd ../../recast3d mkdir build && cd build cmake .. && make This will create a binary recast3d . Test if you can run RECAST3D: ./recast3d This should open an empty white window with a menubar. If you run into any issues, please let us know !","title":"RECAST3D"},{"location":"installation_instructions/#5-testing-the-installation","text":"To test if the SliceRecon software is installed correctly, try the following steps. Start up a RECAST3D instance . Change directories to the recast3d/build directory we made before, and run: ./recast3d Start up a SliceRecon server , that connects to RECAST3D and listens for incoming (projection) data. Change directories to slicerecon/build , and run: ./slicerecon_server --slice-size 512 --preview-size 256 Switching windows to the RECAST3D software, you should see a new scene with empty slices. Pushing data into SliceRecon . The server is unable to reconstruct anything interesting, because it has received no data yet. To push some example data into SliceRecon, we run one of the adapter examples. For example, relative to the recast3d_stack directory: cd examples/adapters python zero_adapter.py This will send data containing zeros to the SliceRecon server.","title":"5. Testing the installation"},{"location":"contribute/design/","text":"Design This developer guide is intended for (future) contributors to the RECAST3D stack. The reference implementation for the quasi-3D reconstruction stack is based on TomoPackets for communication, SliceRecon for reconstruction, and RECAST3D for visualization. G Scanner Scanner Data Adapter Cluster Cluster SliceRecon Scanner->Cluster TomoPackets Workstation(s) Workstations(s) RECAST3D Cluster->Workstation(s) TomoPackets The three components have the following goals: TomoPackets Hide the complexity of making servers and implementing communication Standardize data for real-time tomographic imaging SliceRecon Implement efficient quasi-3d reconstruction Plugin system for research on real-time tomography RECAST3D Allow an operator to visualize the object and interact during a tomographic scan Hopefully, after reading these pages, you will have a good understanding of the overall design of the live reconstruction stack. Distributed approach A distinguishing feature of the stack is that we have taken a fully distributed approach, meaning that any component can run on any node as long as the nodes are connected via a network. This has a number of advantages: We can easily distribute work over clusters We can extend the real-time imaging pipeline using TomoPackets, so that it automatically works with all components of the stack Will be able to switch the underlying technology: each component can be replaced, and new (web-based, VR, \u2026) visualizers can e developed. We can even decide to change the underlying messaging service to something other than ZeroMQ. It is easy to make the stack work for any data source, by writing an adapter for another scanner (or electron microscope, detector at beamline, etc.). The real-time imaging should work all the same. We are able to visualize \u2018remotely\u2019, i.e. on a workstation instead of the terminal attached to the imaging device. We have even shown the feasibility of visualizing in the Netherlands, while reconstruction runs in Switzerland, all without any noticeable lag.","title":"Design"},{"location":"contribute/design/#design","text":"This developer guide is intended for (future) contributors to the RECAST3D stack. The reference implementation for the quasi-3D reconstruction stack is based on TomoPackets for communication, SliceRecon for reconstruction, and RECAST3D for visualization. G Scanner Scanner Data Adapter Cluster Cluster SliceRecon Scanner->Cluster TomoPackets Workstation(s) Workstations(s) RECAST3D Cluster->Workstation(s) TomoPackets The three components have the following goals: TomoPackets Hide the complexity of making servers and implementing communication Standardize data for real-time tomographic imaging SliceRecon Implement efficient quasi-3d reconstruction Plugin system for research on real-time tomography RECAST3D Allow an operator to visualize the object and interact during a tomographic scan Hopefully, after reading these pages, you will have a good understanding of the overall design of the live reconstruction stack.","title":"Design"},{"location":"contribute/design/#distributed-approach","text":"A distinguishing feature of the stack is that we have taken a fully distributed approach, meaning that any component can run on any node as long as the nodes are connected via a network. This has a number of advantages: We can easily distribute work over clusters We can extend the real-time imaging pipeline using TomoPackets, so that it automatically works with all components of the stack Will be able to switch the underlying technology: each component can be replaced, and new (web-based, VR, \u2026) visualizers can e developed. We can even decide to change the underlying messaging service to something other than ZeroMQ. It is easy to make the stack work for any data source, by writing an adapter for another scanner (or electron microscope, detector at beamline, etc.). The real-time imaging should work all the same. We are able to visualize \u2018remotely\u2019, i.e. on a workstation instead of the terminal attached to the imaging device. We have even shown the feasibility of visualizing in the Netherlands, while reconstruction runs in Switzerland, all without any noticeable lag.","title":"Distributed approach"},{"location":"contribute/recast3d/","text":"RECAST3D RECAST3D is based on TomoPackets (ZeroMQ) for communication and OpenGL for visualization. It runs a single server , which communicates with a reconstruction server such as SliceRecon. First, a brief summary of the RECAST3D design. The slicer environment is implemented in ReconstructionComponent , but there is much more in RECAST3D. It has a flexible and transparent server that distributes TomoPackets to modules that want to know about them. Using graphics components and modules, it is easy to extend, improve, or change behaviour. The rendering is based on OpenGL, making it flexible but not trivial to extend. I provide texture, shader, meshes and primitive support, which makes it easier to make a new component. The immediate mode user interface is straightforward to use. Graphics and scenes The software can have multiple scenes. Each scene corresponds to the visualization of a single scan. The important classes that realize the graphics are organized as follows: classDiagram class AxesComponent class GeometryComponent class MeshComponent class ReconstructionComponent class Component { identifier draw() tick() describe() } class SceneObject { camera graphics resources } class Scene { name dimension data } AxesComponent < |-- Component GeometryComponent < |-- Component MeshComponent < |-- Component ReconstructionComponent < |-- Component SceneObject < |-- Scene : Contains Component < |-- SceneObject : Contains The graphics are rendered directly using OpenGL, but there are helper classes available (for primitives, shader programs, textures, and so on). Important shared interfaces for many classes in the graphics implementations are: classDiagram class RenderTarget { render(...) } class Ticker { tick(time_elapsed) } class Window { describe() } class PacketPublisher { send(packet) add_listener(...) } class PacketListener { handle(packet) } PacketPublisher < |-- PacketListener RenderTarget is for any component that wants to be rendered, such as a scene or the user interface. A scene eventually calls draw on its components which takes into account the (3D) camera. Ticker is implemented by any object that wants to update itself over regular time intervals. Window is implemented by any object that wants to add controls to the user interface PacketPublisher and PacketListener allows to easily send packets to upstream components of the reconstruction stack from any point in the graphics (for example, as a side effect due to user input). UI elements We use ImGui for the user interface. This allows parts of the graphics stack to easily draw check boxes, sliders, and text input. This is done through the Window interface. There is also built in support for parameters of upstream components, using the ParameterX packets of TomoPackets. Server The server has a number of \u2018modules\u2019. Each module corresponds to a part of RECAST3D that is interested in handling certain packages. A selection of the implemented modules: classDiagram class SceneModuleProtocol { read_packet(...) process(...) descriptors(...) } ManageSceneProtocol < |-- SceneModuleProtocol ReconstructionProtocol < |-- SceneModuleProtocol GeometryProtocol < |-- SceneModuleProtocol ControlProtocol < |-- SceneModuleProtocol For example, the manage scene protocol listens only to incoming packets of type MakeScenePacket , and whenever one comes in it adds a scene to the scene list. Something to note is that read_packet happens on the server thread, while process happens on the graphics thead. These are kept separate so that all OpenGL calls happen from within a single thread. There is a server running the ZeroMQ REP/REQ protocol that handles incoming packets from upstream (by default on port 5555), and a thread running a PUB/SUB protocol that publishes outgoing packets to (multiple) listeners (by default on port 5556). Example : Reconstruction of a re-oriented slice Let us explore in detail what happens when the user changes a slice. This happens when the user translates along the normal of a slice (using the left mouse button), or rotates around the furthest edge from where they click (using the right button). ReconstructionComponent optionally has a ReconDragMachine which is initiated as soon as the user clicks on the mouse. There are two kinds: a SliceTranslator and a SliceRotator , which both have an on_drag event. stateDiagram Idle --> Translating : left_mouse_down Translating --> Idle : left_mouse_up state Translating { [*] --> [*] : mouse_drag } Idle --> Rotating : right_mouse_down Rotating --> Idle : right_mouse_up state Rotating { [*] --> [*] : mouse_drag } These machines actually deactivate a slice upon creation, and have a reference to a \u2018ghost\u2019 slice that is will be created when the mouse is released. When this new slice is created, we have to let the reconstruction server know that this has occured. A SetSlicePacket is created using the orientation of the newly created slice, and published using the PUB/SUB servers to upstream clients that are subscribed to this packets. For example, SliceRecon registers to this packet. sequenceDiagram participant Component participant SliceRecon participant Protocol Component->>SliceRecon: SetSlicePacket SliceRecon->>Protocol: SliceDataPacket Protocol->>Component: set_data(...) The reconstruction server then computes a slice reconstruction for the slice, and sends this to the incoming port of RECAST3D (the REQ/REP server). This is eventually handled by the ReconstructionProtocol that listens to SliceDataPackets . When this protocol handles the request, it updates the data of the corresponding scene, and this is ultimately reflected in the ReconstructionComponent which then shows the updated slice. Note that this entire sequence happens within milliseconds, and is entirely distributed: RECAST3D and the reconstruction server do not have to run on the same computer, and in fact any agent can act as the reconstruction server. Example : Extend RECAST3D to add control parameters As an example of a feature that was added to RECAST3D, let\u2019s discuss the steps it took to add control parameters to RECAST3D. The idea of control parameters is that upstream components can register a \u2018parameter\u2019 with RECAST3D, which then shows a UI element to change this parameter. When the user changes one of these parameters using the UI, a packet has to be sent to the upstream component that it belongs to. Control packets were added to TomoPackets (e.g. ParameterBoolPacket ) A ControlComponent and a ControlModule were added to RECAST3D. Note that the control component does not draw anything in the 3D window, but only wants to add additional UI elements. The ControlModule registers itself as the handler for e.g. the ParameterBoolPacket and others (actual implementation also includes benchmarking, and tracking). When a ParameterBoolPacket is received by the module it gets sent to the appropriate ControlComponent . The implementation of the ControlComponent : In describe() , for drawing UI elements: one checkbox for each known parameter. If checkbox changed by user, we send a ParameterBoolPacket downstream. After these changes, we can use this for real-time alignment parameter adjustment, changing filters, and so on, all without touching existing code in RECAST3D.","title":"RECAST3D"},{"location":"contribute/recast3d/#recast3d","text":"RECAST3D is based on TomoPackets (ZeroMQ) for communication and OpenGL for visualization. It runs a single server , which communicates with a reconstruction server such as SliceRecon. First, a brief summary of the RECAST3D design. The slicer environment is implemented in ReconstructionComponent , but there is much more in RECAST3D. It has a flexible and transparent server that distributes TomoPackets to modules that want to know about them. Using graphics components and modules, it is easy to extend, improve, or change behaviour. The rendering is based on OpenGL, making it flexible but not trivial to extend. I provide texture, shader, meshes and primitive support, which makes it easier to make a new component. The immediate mode user interface is straightforward to use.","title":"RECAST3D"},{"location":"contribute/recast3d/#graphics-and-scenes","text":"The software can have multiple scenes. Each scene corresponds to the visualization of a single scan. The important classes that realize the graphics are organized as follows: classDiagram class AxesComponent class GeometryComponent class MeshComponent class ReconstructionComponent class Component { identifier draw() tick() describe() } class SceneObject { camera graphics resources } class Scene { name dimension data } AxesComponent < |-- Component GeometryComponent < |-- Component MeshComponent < |-- Component ReconstructionComponent < |-- Component SceneObject < |-- Scene : Contains Component < |-- SceneObject : Contains The graphics are rendered directly using OpenGL, but there are helper classes available (for primitives, shader programs, textures, and so on). Important shared interfaces for many classes in the graphics implementations are: classDiagram class RenderTarget { render(...) } class Ticker { tick(time_elapsed) } class Window { describe() } class PacketPublisher { send(packet) add_listener(...) } class PacketListener { handle(packet) } PacketPublisher < |-- PacketListener RenderTarget is for any component that wants to be rendered, such as a scene or the user interface. A scene eventually calls draw on its components which takes into account the (3D) camera. Ticker is implemented by any object that wants to update itself over regular time intervals. Window is implemented by any object that wants to add controls to the user interface PacketPublisher and PacketListener allows to easily send packets to upstream components of the reconstruction stack from any point in the graphics (for example, as a side effect due to user input).","title":"Graphics and scenes"},{"location":"contribute/recast3d/#ui-elements","text":"We use ImGui for the user interface. This allows parts of the graphics stack to easily draw check boxes, sliders, and text input. This is done through the Window interface. There is also built in support for parameters of upstream components, using the ParameterX packets of TomoPackets.","title":"UI elements"},{"location":"contribute/recast3d/#server","text":"The server has a number of \u2018modules\u2019. Each module corresponds to a part of RECAST3D that is interested in handling certain packages. A selection of the implemented modules: classDiagram class SceneModuleProtocol { read_packet(...) process(...) descriptors(...) } ManageSceneProtocol < |-- SceneModuleProtocol ReconstructionProtocol < |-- SceneModuleProtocol GeometryProtocol < |-- SceneModuleProtocol ControlProtocol < |-- SceneModuleProtocol For example, the manage scene protocol listens only to incoming packets of type MakeScenePacket , and whenever one comes in it adds a scene to the scene list. Something to note is that read_packet happens on the server thread, while process happens on the graphics thead. These are kept separate so that all OpenGL calls happen from within a single thread. There is a server running the ZeroMQ REP/REQ protocol that handles incoming packets from upstream (by default on port 5555), and a thread running a PUB/SUB protocol that publishes outgoing packets to (multiple) listeners (by default on port 5556).","title":"Server"},{"location":"contribute/recast3d/#example-reconstruction-of-a-re-oriented-slice","text":"Let us explore in detail what happens when the user changes a slice. This happens when the user translates along the normal of a slice (using the left mouse button), or rotates around the furthest edge from where they click (using the right button). ReconstructionComponent optionally has a ReconDragMachine which is initiated as soon as the user clicks on the mouse. There are two kinds: a SliceTranslator and a SliceRotator , which both have an on_drag event. stateDiagram Idle --> Translating : left_mouse_down Translating --> Idle : left_mouse_up state Translating { [*] --> [*] : mouse_drag } Idle --> Rotating : right_mouse_down Rotating --> Idle : right_mouse_up state Rotating { [*] --> [*] : mouse_drag } These machines actually deactivate a slice upon creation, and have a reference to a \u2018ghost\u2019 slice that is will be created when the mouse is released. When this new slice is created, we have to let the reconstruction server know that this has occured. A SetSlicePacket is created using the orientation of the newly created slice, and published using the PUB/SUB servers to upstream clients that are subscribed to this packets. For example, SliceRecon registers to this packet. sequenceDiagram participant Component participant SliceRecon participant Protocol Component->>SliceRecon: SetSlicePacket SliceRecon->>Protocol: SliceDataPacket Protocol->>Component: set_data(...) The reconstruction server then computes a slice reconstruction for the slice, and sends this to the incoming port of RECAST3D (the REQ/REP server). This is eventually handled by the ReconstructionProtocol that listens to SliceDataPackets . When this protocol handles the request, it updates the data of the corresponding scene, and this is ultimately reflected in the ReconstructionComponent which then shows the updated slice. Note that this entire sequence happens within milliseconds, and is entirely distributed: RECAST3D and the reconstruction server do not have to run on the same computer, and in fact any agent can act as the reconstruction server.","title":"Example: Reconstruction of a re-oriented slice"},{"location":"contribute/recast3d/#example-extend-recast3d-to-add-control-parameters","text":"As an example of a feature that was added to RECAST3D, let\u2019s discuss the steps it took to add control parameters to RECAST3D. The idea of control parameters is that upstream components can register a \u2018parameter\u2019 with RECAST3D, which then shows a UI element to change this parameter. When the user changes one of these parameters using the UI, a packet has to be sent to the upstream component that it belongs to. Control packets were added to TomoPackets (e.g. ParameterBoolPacket ) A ControlComponent and a ControlModule were added to RECAST3D. Note that the control component does not draw anything in the 3D window, but only wants to add additional UI elements. The ControlModule registers itself as the handler for e.g. the ParameterBoolPacket and others (actual implementation also includes benchmarking, and tracking). When a ParameterBoolPacket is received by the module it gets sent to the appropriate ControlComponent . The implementation of the ControlComponent : In describe() , for drawing UI elements: one checkbox for each known parameter. If checkbox changed by user, we send a ParameterBoolPacket downstream. After these changes, we can use this for real-time alignment parameter adjustment, changing filters, and so on, all without touching existing code in RECAST3D.","title":"Example: Extend RECAST3D to add control parameters"},{"location":"contribute/slicerecon/","text":"SliceRecon Overview The SliceRecon project defines three main objects: A projection server, that listens to incoming projection data. A reconstructor, that can reconstruct arbitrarily oriented slices from projection data. A visualization server, that listens to requests from a visualization server, and fulfils them by calling the reconstructor. Furthermore, it has a notion of a plugin, which is a stand alone server that can postprocess reconstructed slices before sending them to the visualization server. The incoming, internal, and outgoing communication is all handled by the TomoPackets library. Projection server The projection server listens for incoming data packets. It expects first packets that describe the tomographic scan. This is done using: GeometrySpecification : information on where the object is in relation to the acquisition geometry. ScanSettings packet: information on the number of darks and flats. A packet describing the acquisition geometry, such as a ConeVecGeometry packet. After receiving these packets, the server is able to process ProjectionData packets. First the darks and flats should be sent, after which standard projections can be streamed to the projection server. Reconstructor The reconstructor is an internal object that decouples the projection server from the visualization server, and has no public interface. It receives projection data from the projection server, and fulfills reconstruction requests from the visualization server. Visualization server The visualization server registers itself to the visualization software by sending a MakeScene packet. It then waits to receive KillScene , SetSlice and RemoveSlice packets. If it receives a SetSlice packet, it requests a new slice reconstruction from the reconstructor. It sends this reconstructed slice back either to the visualization software using a SliceData packet if there are no active plugins, or to the first plugin. Plugin A plugin is a simple server, that registers itself to the visualization server, and listens to incoming SliceData packets. It then manipulates the data in this SliceData packet, before sending it along to the next plugin in line, or to the visualization software. The plugin system thus has the following structure: graph LR reconstructor[Reconstructor] plugin[\"Plugin(s)\"] visualizer[Visualizer] visualizer-- set slice -->reconstructor reconstructor-. slice data.->visualizer reconstructor-- slice data -->plugin plugin-- slice data -->visualizer There can be more than one plugin, but they are assumed to be applied one after the other. The dashed line is only used if there are no plugins. Conventions Multi-dimensional arrays Volume data is stored in x-y-z order (from major to minor). Projection data is stored in row-column order (from major to minor). SliceRecon architecture An overview of the design of SliceRecon is as follows. graph TB projection_data[(Projection Data)] recast3d[RECAST3D] projection_server[/projection_server/] reconstructor[/reconstructor/] buffer1[inactive buffer] buffer2[active buffer] solver[/solver/] visualization_server[/visualization_server/] projection_data-->projection_server subgraph SliceRecon projection_server-- scan settings -->reconstructor projection_server-- geometry -->reconstructor projection_server-. projections .->reconstructor reconstructor-- preprocessed projections -->buffer1 buffer1-- swap -->buffer2 buffer2-- swap -->buffer1 buffer2-->solver visualization_server-- requests/configuration -->solver solver-- reconstructions -->visualization_server end visualization_server --> recast3d When projection data comes into SliceRecon, it gets put into an \u2018inactive buffer\u2019. As soon as enough projection data is processed and in main RAM, we \u2018upload\u2019 to the GPU. This happens in a number of steps: pre-process flat fielding FDK scaling filtering phase retrieval \u2026 transpose sinogram upload to GPU There are two modes, alternating and continuous . In \u2018alternating\u2019 mode, we always reconstruct from the last complete set of projections. In \u2018continuous mode\u2019 we reconstruct with for each projection the most recent data. Data flowing in/out of SliceRecon classDiagram class Adapter { scan settings vol_geom proj_geom [projection] } class User Settings { slice_size preview_size group_size filter_cores } class projection_server class visualization_server class solver class Plugins class RECAST3D projection_server < |.. Adapter projection_server < |-- User Settings visualization_server < |-- solver : reconstructions solver < |-- projection_server Plugins < |.. visualization_server : reconstructions RECAST3D < |.. Plugins visualization_server < |.. RECAST3D : requests solver < |-- visualization_server : requests Solid lines happen within SliceRecon, while dashed lines are communicated using TomoPackets. Solver implementation The solver can reconstruct an arbitrarily oriented slice from the full 3D projection data. Instead of considering the full 3D volume, we setup our geometry by constructing an object volume that consists of the central axial slice C C only. If we want to reconstruct an arbitrary slice S S , we can transform S S into C C using a combination of a translation vector \\delta \\delta from the center of slice S S onto the center of C C (and thus the full 3D volume), a rotation \\mathcal{R} \\mathcal{R} , and optionally a scale factor which does not have to be used when slices are of fixed size. For a cone-beam geometry, we can define each projection by a source position \\vec{s} \\vec{s} , a detector position \\vec{d} \\vec{d} , and two axes \\vec{u} \\vec{u} and \\vec{v} \\vec{v} that define pixel distances on the detector. We then transform each projection according to: \\begin{align*} \\vec{s}' &= \\mathcal{R} (\\vec{s} + \\delta) \\\\ \\vec{d}' &= \\mathcal{R} (\\vec{d} + \\delta) \\\\ \\vec{u}' &= \\mathcal{R} (\\vec{u}) \\\\ \\vec{v}' &= \\mathcal{R} (\\vec{v}) \\end{align*} \\begin{align*} \\vec{s}' &= \\mathcal{R} (\\vec{s} + \\delta) \\\\ \\vec{d}' &= \\mathcal{R} (\\vec{d} + \\delta) \\\\ \\vec{u}' &= \\mathcal{R} (\\vec{u}) \\\\ \\vec{v}' &= \\mathcal{R} (\\vec{v}) \\end{align*} If we then reconstruct with the transformed geometry, we are effectively using a geometry in which the arbitrary slice S S has become the central slice, without having to adjust the projection data. This is the basic idea behind the solver implementation: we adjust the geometry on the fly for each slice that we are interested in, and then run a standard backprojection algorithm.","title":"SliceRecon"},{"location":"contribute/slicerecon/#slicerecon","text":"","title":"SliceRecon"},{"location":"contribute/slicerecon/#overview","text":"The SliceRecon project defines three main objects: A projection server, that listens to incoming projection data. A reconstructor, that can reconstruct arbitrarily oriented slices from projection data. A visualization server, that listens to requests from a visualization server, and fulfils them by calling the reconstructor. Furthermore, it has a notion of a plugin, which is a stand alone server that can postprocess reconstructed slices before sending them to the visualization server. The incoming, internal, and outgoing communication is all handled by the TomoPackets library.","title":"Overview"},{"location":"contribute/slicerecon/#projection-server","text":"The projection server listens for incoming data packets. It expects first packets that describe the tomographic scan. This is done using: GeometrySpecification : information on where the object is in relation to the acquisition geometry. ScanSettings packet: information on the number of darks and flats. A packet describing the acquisition geometry, such as a ConeVecGeometry packet. After receiving these packets, the server is able to process ProjectionData packets. First the darks and flats should be sent, after which standard projections can be streamed to the projection server.","title":"Projection server"},{"location":"contribute/slicerecon/#reconstructor","text":"The reconstructor is an internal object that decouples the projection server from the visualization server, and has no public interface. It receives projection data from the projection server, and fulfills reconstruction requests from the visualization server.","title":"Reconstructor"},{"location":"contribute/slicerecon/#visualization-server","text":"The visualization server registers itself to the visualization software by sending a MakeScene packet. It then waits to receive KillScene , SetSlice and RemoveSlice packets. If it receives a SetSlice packet, it requests a new slice reconstruction from the reconstructor. It sends this reconstructed slice back either to the visualization software using a SliceData packet if there are no active plugins, or to the first plugin.","title":"Visualization server"},{"location":"contribute/slicerecon/#plugin","text":"A plugin is a simple server, that registers itself to the visualization server, and listens to incoming SliceData packets. It then manipulates the data in this SliceData packet, before sending it along to the next plugin in line, or to the visualization software. The plugin system thus has the following structure: graph LR reconstructor[Reconstructor] plugin[\"Plugin(s)\"] visualizer[Visualizer] visualizer-- set slice -->reconstructor reconstructor-. slice data.->visualizer reconstructor-- slice data -->plugin plugin-- slice data -->visualizer There can be more than one plugin, but they are assumed to be applied one after the other. The dashed line is only used if there are no plugins.","title":"Plugin"},{"location":"contribute/slicerecon/#conventions","text":"","title":"Conventions"},{"location":"contribute/slicerecon/#multi-dimensional-arrays","text":"Volume data is stored in x-y-z order (from major to minor). Projection data is stored in row-column order (from major to minor).","title":"Multi-dimensional arrays"},{"location":"contribute/slicerecon/#slicerecon-architecture","text":"An overview of the design of SliceRecon is as follows. graph TB projection_data[(Projection Data)] recast3d[RECAST3D] projection_server[/projection_server/] reconstructor[/reconstructor/] buffer1[inactive buffer] buffer2[active buffer] solver[/solver/] visualization_server[/visualization_server/] projection_data-->projection_server subgraph SliceRecon projection_server-- scan settings -->reconstructor projection_server-- geometry -->reconstructor projection_server-. projections .->reconstructor reconstructor-- preprocessed projections -->buffer1 buffer1-- swap -->buffer2 buffer2-- swap -->buffer1 buffer2-->solver visualization_server-- requests/configuration -->solver solver-- reconstructions -->visualization_server end visualization_server --> recast3d When projection data comes into SliceRecon, it gets put into an \u2018inactive buffer\u2019. As soon as enough projection data is processed and in main RAM, we \u2018upload\u2019 to the GPU. This happens in a number of steps: pre-process flat fielding FDK scaling filtering phase retrieval \u2026 transpose sinogram upload to GPU There are two modes, alternating and continuous . In \u2018alternating\u2019 mode, we always reconstruct from the last complete set of projections. In \u2018continuous mode\u2019 we reconstruct with for each projection the most recent data.","title":"SliceRecon architecture"},{"location":"contribute/slicerecon/#data-flowing-inout-of-slicerecon","text":"classDiagram class Adapter { scan settings vol_geom proj_geom [projection] } class User Settings { slice_size preview_size group_size filter_cores } class projection_server class visualization_server class solver class Plugins class RECAST3D projection_server < |.. Adapter projection_server < |-- User Settings visualization_server < |-- solver : reconstructions solver < |-- projection_server Plugins < |.. visualization_server : reconstructions RECAST3D < |.. Plugins visualization_server < |.. RECAST3D : requests solver < |-- visualization_server : requests Solid lines happen within SliceRecon, while dashed lines are communicated using TomoPackets.","title":"Data flowing in/out of SliceRecon"},{"location":"contribute/slicerecon/#solver-implementation","text":"The solver can reconstruct an arbitrarily oriented slice from the full 3D projection data. Instead of considering the full 3D volume, we setup our geometry by constructing an object volume that consists of the central axial slice C C only. If we want to reconstruct an arbitrary slice S S , we can transform S S into C C using a combination of a translation vector \\delta \\delta from the center of slice S S onto the center of C C (and thus the full 3D volume), a rotation \\mathcal{R} \\mathcal{R} , and optionally a scale factor which does not have to be used when slices are of fixed size. For a cone-beam geometry, we can define each projection by a source position \\vec{s} \\vec{s} , a detector position \\vec{d} \\vec{d} , and two axes \\vec{u} \\vec{u} and \\vec{v} \\vec{v} that define pixel distances on the detector. We then transform each projection according to: \\begin{align*} \\vec{s}' &= \\mathcal{R} (\\vec{s} + \\delta) \\\\ \\vec{d}' &= \\mathcal{R} (\\vec{d} + \\delta) \\\\ \\vec{u}' &= \\mathcal{R} (\\vec{u}) \\\\ \\vec{v}' &= \\mathcal{R} (\\vec{v}) \\end{align*} \\begin{align*} \\vec{s}' &= \\mathcal{R} (\\vec{s} + \\delta) \\\\ \\vec{d}' &= \\mathcal{R} (\\vec{d} + \\delta) \\\\ \\vec{u}' &= \\mathcal{R} (\\vec{u}) \\\\ \\vec{v}' &= \\mathcal{R} (\\vec{v}) \\end{align*} If we then reconstruct with the transformed geometry, we are effectively using a geometry in which the arbitrary slice S S has become the central slice, without having to adjust the projection data. This is the basic idea behind the solver implementation: we adjust the geometry on the fly for each slice that we are interested in, and then run a standard backprojection algorithm.","title":"Solver implementation"},{"location":"contribute/tomopackets/","text":"This library implements a communication protocol for a distributed tomographic reconstruction pipeline in which parameters used in the reconstruction can be changed in real-time, taking effect on the running reconstruction code immediately. The protocol is based on the reconstruction of individual slices, for example orthogonal planes, and is useful for situations where the projection data is to big to reconstruct completely in real-time. The slices are shown together in a 3D interface, and get updated when, for example: new (projection) data is available more iterations for iterative solvers have been applied higher resolution reconstructions are available The position and orientation of the active slices can be changed, and this is communicated back to the reconstruction cluster, which for future updates will then reconstruct these new slices. Pipeline For real-time imaging experiments, there are many nodes at work at the same time. A rough overview of the topology that is recommended (but not required) for communication based on TomoPackets is as follows. G Scan Data Scan Data Adapter Adapter Scan Data->Adapter Reconstructor Reconstructor Adapter->Reconstructor Visualizer Visualizer Reconstructor->Visualizer Plugin Plugin Reconstructor->Plugin Visualizer->Reconstructor ... ... Plugin->... ...->Visualizer We have the following node types. Scan Data . The entry point of the pipeline: data coming from the detector which get pushed into the network. This data can also come from simulations or be prerecorded. Adapter . This node is specific to the projection data, and metadata about the acquistion. It converts this application specific data, to a common format that can be used by nodes further down the pipeline that implement the TomoPackets protocol. Some adapter examples can be found in the slicerecon_ project. Reconstructor . This node receives projection data and metadata, and uses it it to fulfil reconstruction requests from visualization nodes further down the line. The slicerecon_ project implements such a node. Plugins . Plugin nodes take reconstructed slices, and postprocess them. For example, for real-time segmentation, artefact removal, other image enhancements, or quantitative analysis of the imaged object. If there are no active plugins, the reconstructed slice given by the reconstructor is sent directly to the visualization node. Example plugins can also be found in the slicerecon_ project. Visualizer . The visualization node shows the reconstructions to a user. When the user changes the slices that are being reconstructed, the visualizer requests a new reconstruction from the reconstructor. An example visualizer is the RECAST3D_ software. Packets A packet is a group of data that has to be sent together. These can be 2D reconstructions, 3D reconstructions, but also slice reconstruction request, and so on. The TomoPackets implementation automates a lot of boilerplate for the developer, and automatically takes care of a lot things such as: Serializing Deserializing \u2018Measuring\u2019 Sending over network Generating Python bindings with docs. This required some template magic, which luckily is not necessary to understand in order to make new packets. struct Packet { // ... send ( zmq :: socket_t & socket ); std :: size_t size () const ; memory_buffer serialize ( int size ) const ; void deserialize ( memory_buffer buffer ); }; TomoPackets is a flexible system, high-performance, easy to extend, and automatically ready to be used in real-time experiments. It abstracts away the whole \u2018distributed part\u2019 of the real-time reconstruction pipeline, so that adding features are just as easy as if it was all local. Automatically serialize/deserialize, send over network, and use other languages like Python in the real-time stack. Has built-in servers so that (in principle) clients do not have to rely explicitly on ZeroMQ. Descriptors Each packet has a \u2018descriptor\u2019, which is a number to identify the content of the packet. The descriptors can be found in descriptors.hpp . enum class packet_desc : int { // SCENE MANAGEMENT make_scene = 0x101 , kill_scene = 0x102 , // RECONSTRUCTION slice_data = 0x201 , partial_slice_data = 0x202 , volume_data = 0x203 , ... Defining a new packet A new packet is defined using code such as the following. struct RegularizationParameterPacket : public PacketBase < RegularizationParameterPacket > { static const auto desc = packet_desc :: regularization_parameter ; RegularizationParameterPacket () = default ; RegularizationParameterPacket ( int32_t a , float b ) : scene_id ( a ), lambda ( b ) {} BOOST_HANA_DEFINE_STRUCT ( RegularizationParameterPacket , ( int32_t , scene_id ), ( float , lambda )); }; This might seem more complex compared to defining a simple struct, such as: struct RegularizationParameterPacket : public Packet { int32_t scene_id ; float lambda ; packet_desc desc = packet_desc :: regularization_parameter ; }; However, we get a lot in return. Code is automatically generated for networking (serialization, deserialization, measuring, sending, etc.), Python bindings, and the documentation. We have to perform two additional actions: add \u2018regularization_parameter\u2019 to descriptor enum, and optionally add it to the list of packets to expose to Python in tomop/module.cpp Serialization Packets can contain components that are trivially copyable, and std::string (Python strings) and std::vector (Python lists / numpy arrays). To make a packet with a more exotic component, specialize operator<< and operator>> for memory_span in serialize.hpp . Hierarchy of packet classes / implementation A schematic overview of the relevant classes and funtionality for the packets is as follows. G DerivedPacket DerivedPacket PacketBase PacketBase[DerivedPacket] serialize deserialize size DerivedPacket->PacketBase Packet Packet PacketBase->Packet omembuf omembuf omembuf->Packet imembuf imembuf imembuf->Packet memory_buffer memory_buffer memory_buffer->omembuf memory_buffer->imembuf fill fill fill->PacketBase scale scale scale->Packet Here, solid lines denote inheritence, and dotted lines mean the source is used by the target. The magic that allows everything to be generated automatically, is the fill function: template < typename Derived , typename Buffer > void fill ( Derived & base , Buffer & buffer ) { hana :: for_each ( hana :: accessors < Derived > (), [ & ]( auto pair ) { buffer | hana :: second ( pair )( base ); }); } Every struct for a given functionality (serializing, deserializing and so on) overloads operator| , and this function iteratively calls this operator for each member of the packet. This is also the way the Python bindings are setup. No manual code required . Sending and receiving packets Each packet has a send(socket) function that allows it to be sent over any ZeroMQ socket. TomoPackets also has a built-in \u2018server\u2019. A tomop::server actually runs two independent \u2018servers\u2019: one for receiving projections, and one reconstruction server to respond to slice requests This is also where the descriptors come in: anything but packet_desc::set_slice, packet_desc::remove_slice, packet_desc::kill_scene are for example ignored by the \u2018reconstruction\u2019 server, while the projection server only listens to packet_desc::projection_data . You can use: set_slice_callback(callback_type callback) for adding custom reconstruction code and set_projection_callback(projection_callback_type callback) to handle new projections from the scanner. There is also a \u2018multiserver\u2019, which allows connections to more than one visualization tool (RECAST3D). It is also possible to make custom servers which is what SliceRecon and RECAST3D do: Make a ZeroMQ socket to receive messages Read the descriptor, and deserialize the message based on the descriptor. After this, handle the packet using its contents. Example code for custom server: socket_ . recv ( & update ); auto desc = (( tomop :: packet_desc * ) update . data ())[ 0 ]; switch ( desc ) { case tomop :: packet_desc :: scan_settings : { auto mbuffer = tomop :: memory_buffer ( update . size (), ( char * ) update . data ()); auto packet = std :: make_unique < tomop :: ScanSettingsPacket > (); packet -> deserialize ( std :: move ( mbuffer )); // ... Examples The communication between nodes happens in a using standardized network packets that contain data, commands, or parameters. Here we give some examples of these packets. Adapter to Reconstructor The reconstructor needs to receive three types of information from the data adapter. Information about where the object is positioned in relation to the acquisition geometry. This is done using a tomop.geometry_specification_packet , which defines the minimum and maximum point of a bounding box around the object, which is the physical region to be reconstructed. Information of the acquisition geometry. This is done using either of the following four packets. tomop.parallel_beam_geometry_packet tomop.parallel_vec_geometry_packet tomop.cone_beam_geometry_packet tomop.cone_vec_geometry_packet The projection data. This is done using (multiple) tomop.projection_packet . The type field of his packet denotes dark ( 0 ), bright ( 1 ), or ordinary ( 2 ) projections. Reconstructor to/from Visualizer The communication between the reconstructor and visualizer uses the following packets. To construct a scene, a tomop.make_scene_packet is sent to the visualizer. This is done over a REQ/REP channel, the reply is the assigned scene_id which can be used to tag later packets. After the scene is constructed, the reconstructor waits to receive tomop.set_slice_packet requests. It responds to these packets using a tomop.slice_data_packet . If there are plugins active, this packet is sent to the first plugin in line, which sends it to the next plugin after it is done processing. The final plugin then sends it to the visualizer. Other uses Plugin system: make a server that reads a SliceDataPacket, modifies it and sends it along the pipeline. Only necessary change: slice data gets sent to plugin socket instead of RECAST, while plugin forwards it to RECAST Real-time alignment: e.g. send a control packet \u2018rotation_axis\u2019. This creates a slider in RECAST, and the reconstruction software gets notified when the user changes this. Can also be used for checkboxes (Gaussian pass, Paganin, \u2026), or drop down menus (changes FBP filter used, \u2026) Multi-GPU FBP/FDK reconstruction distribute ProjectionDataPackets round robin, and sum the resulting \u2018SliceDataPacket\u2019s at RECAST3D (using the member \u2018additive\u2019). Conventions Multi-dimensional arrays Volume data is stored in x-y-z order (from major to minor). Projection data is stored in row-column order (from major to minor). Slice orientation We need a convention for representing the orientation of a slice. The orientation is inside volume space and is completely independent from the number of pixels (i.e. the \u2018size\u2019 of an individual pixel is implied by the bounding square of a slice). We represent the orientation as 9 real numbers (a, b, \\ldots, i) (a, b, \\ldots, i) so that: \\begin{equation} \\begin{pmatrix} a & d & g \\\\ b & e & h \\\\ c & f & i \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_s \\\\ y_s \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x_w \\\\ y_w \\\\ z_w \\\\ 1 \\end{pmatrix} \\end{equation} \\begin{equation} \\begin{pmatrix} a & d & g \\\\ b & e & h \\\\ c & f & i \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_s \\\\ y_s \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x_w \\\\ y_w \\\\ z_w \\\\ 1 \\end{pmatrix} \\end{equation} Where the vector \\vec{x}_s = (x_s, y_s) \\vec{x}_s = (x_s, y_s) lives inside a slice (i.e. the normalized pixel coordinates of a slice, in the interval [0, 1] [0, 1] ), and where \\vec{x}_w = (x_w, y_w, z_w) \\vec{x}_w = (x_w, y_w, z_w) lives inside the volume geometry at the correct place. The pixel coordinates of a slice have the following convention: \\begin{equation} \\begin{pmatrix} (0, m) & \\cdots & (n, m) \\\\ \\vdots & \\ddots & \\vdots \\\\ (0, 0) & \\cdots & (n, 0) \\end{pmatrix} \\end{equation} \\begin{equation} \\begin{pmatrix} (0, m) & \\cdots & (n, m) \\\\ \\vdots & \\ddots & \\vdots \\\\ (0, 0) & \\cdots & (n, 0) \\end{pmatrix} \\end{equation} i.e. we start counting from the bottom-left and use a standard cartesian xy xy convention. Using this convention, the vector \\vec{b} = (g, h, i) \\vec{b} = (g, h, i) is the base point of the slice in world space (i.e. the world coordinates of the bottom left point of a slice). \\vec{x} = (a,b,c) \\vec{x} = (a,b,c) is the direction in world space corresponding to the x x direction of the slice, and \\vec{y} = (d, e, f) \\vec{y} = (d, e, f) corresponds to the y y direction. Acquisition geometries The fields of the acquisition geometry packets: tomop.parallel_beam_geometry_packet tomop.parallel_vec_geometry_packet tomop.cone_beam_geometry_packet tomop.cone_vec_geometry_packet follow the conventions of the constructors of 3D Geometries of the ASTRA Toolbox. See http://www.astra-toolbox.com/docs/geom3d.html for an overview. Usage Writing a reconstruction node For writing a simple reconstructor that responds to slice reconstruction requests, you can use tomop.server and set a callback. You can also send other types of packets over the channel opened by this server. For example, sending a tomop.volume_data_packet enables a visualizer to show a 3D preview:: import tomop import numpy as np def callback ( orientation , slice_id ): print ( \"callback called\" ) print ( orientation ) return [ 4 , 4 ], np . array ([ 0 , 255 , 0 , 255 , 255 , 0 , 255 , 0 , 255 , 0 , 0 , 255 , 255 , 0 , 0 , 255 ], dtype = 'float32' ) serv = tomop . server ( \"scene name\" ) vdp = tomop . volume_data_packet ( serv . scene_id (), np . array ([ 2 , 2 , 2 ], dtype = 'int32' ) . tolist (), np . array ([ 0 , 255 , 128 , 255 , 255 , 128 , 255 , 0 ], dtype = 'float32' )) serv . send ( vdp ) serv . set_callback ( callback ) serv . serve ()","title":"TomoPackets"},{"location":"contribute/tomopackets/#pipeline","text":"For real-time imaging experiments, there are many nodes at work at the same time. A rough overview of the topology that is recommended (but not required) for communication based on TomoPackets is as follows. G Scan Data Scan Data Adapter Adapter Scan Data->Adapter Reconstructor Reconstructor Adapter->Reconstructor Visualizer Visualizer Reconstructor->Visualizer Plugin Plugin Reconstructor->Plugin Visualizer->Reconstructor ... ... Plugin->... ...->Visualizer We have the following node types. Scan Data . The entry point of the pipeline: data coming from the detector which get pushed into the network. This data can also come from simulations or be prerecorded. Adapter . This node is specific to the projection data, and metadata about the acquistion. It converts this application specific data, to a common format that can be used by nodes further down the pipeline that implement the TomoPackets protocol. Some adapter examples can be found in the slicerecon_ project. Reconstructor . This node receives projection data and metadata, and uses it it to fulfil reconstruction requests from visualization nodes further down the line. The slicerecon_ project implements such a node. Plugins . Plugin nodes take reconstructed slices, and postprocess them. For example, for real-time segmentation, artefact removal, other image enhancements, or quantitative analysis of the imaged object. If there are no active plugins, the reconstructed slice given by the reconstructor is sent directly to the visualization node. Example plugins can also be found in the slicerecon_ project. Visualizer . The visualization node shows the reconstructions to a user. When the user changes the slices that are being reconstructed, the visualizer requests a new reconstruction from the reconstructor. An example visualizer is the RECAST3D_ software.","title":"Pipeline"},{"location":"contribute/tomopackets/#packets","text":"A packet is a group of data that has to be sent together. These can be 2D reconstructions, 3D reconstructions, but also slice reconstruction request, and so on. The TomoPackets implementation automates a lot of boilerplate for the developer, and automatically takes care of a lot things such as: Serializing Deserializing \u2018Measuring\u2019 Sending over network Generating Python bindings with docs. This required some template magic, which luckily is not necessary to understand in order to make new packets. struct Packet { // ... send ( zmq :: socket_t & socket ); std :: size_t size () const ; memory_buffer serialize ( int size ) const ; void deserialize ( memory_buffer buffer ); }; TomoPackets is a flexible system, high-performance, easy to extend, and automatically ready to be used in real-time experiments. It abstracts away the whole \u2018distributed part\u2019 of the real-time reconstruction pipeline, so that adding features are just as easy as if it was all local. Automatically serialize/deserialize, send over network, and use other languages like Python in the real-time stack. Has built-in servers so that (in principle) clients do not have to rely explicitly on ZeroMQ.","title":"Packets"},{"location":"contribute/tomopackets/#descriptors","text":"Each packet has a \u2018descriptor\u2019, which is a number to identify the content of the packet. The descriptors can be found in descriptors.hpp . enum class packet_desc : int { // SCENE MANAGEMENT make_scene = 0x101 , kill_scene = 0x102 , // RECONSTRUCTION slice_data = 0x201 , partial_slice_data = 0x202 , volume_data = 0x203 , ...","title":"Descriptors"},{"location":"contribute/tomopackets/#defining-a-new-packet","text":"A new packet is defined using code such as the following. struct RegularizationParameterPacket : public PacketBase < RegularizationParameterPacket > { static const auto desc = packet_desc :: regularization_parameter ; RegularizationParameterPacket () = default ; RegularizationParameterPacket ( int32_t a , float b ) : scene_id ( a ), lambda ( b ) {} BOOST_HANA_DEFINE_STRUCT ( RegularizationParameterPacket , ( int32_t , scene_id ), ( float , lambda )); }; This might seem more complex compared to defining a simple struct, such as: struct RegularizationParameterPacket : public Packet { int32_t scene_id ; float lambda ; packet_desc desc = packet_desc :: regularization_parameter ; }; However, we get a lot in return. Code is automatically generated for networking (serialization, deserialization, measuring, sending, etc.), Python bindings, and the documentation. We have to perform two additional actions: add \u2018regularization_parameter\u2019 to descriptor enum, and optionally add it to the list of packets to expose to Python in tomop/module.cpp","title":"Defining a new packet"},{"location":"contribute/tomopackets/#serialization","text":"Packets can contain components that are trivially copyable, and std::string (Python strings) and std::vector (Python lists / numpy arrays). To make a packet with a more exotic component, specialize operator<< and operator>> for memory_span in serialize.hpp .","title":"Serialization"},{"location":"contribute/tomopackets/#hierarchy-of-packet-classes-implementation","text":"A schematic overview of the relevant classes and funtionality for the packets is as follows. G DerivedPacket DerivedPacket PacketBase PacketBase[DerivedPacket] serialize deserialize size DerivedPacket->PacketBase Packet Packet PacketBase->Packet omembuf omembuf omembuf->Packet imembuf imembuf imembuf->Packet memory_buffer memory_buffer memory_buffer->omembuf memory_buffer->imembuf fill fill fill->PacketBase scale scale scale->Packet Here, solid lines denote inheritence, and dotted lines mean the source is used by the target. The magic that allows everything to be generated automatically, is the fill function: template < typename Derived , typename Buffer > void fill ( Derived & base , Buffer & buffer ) { hana :: for_each ( hana :: accessors < Derived > (), [ & ]( auto pair ) { buffer | hana :: second ( pair )( base ); }); } Every struct for a given functionality (serializing, deserializing and so on) overloads operator| , and this function iteratively calls this operator for each member of the packet. This is also the way the Python bindings are setup. No manual code required .","title":"Hierarchy of packet classes / implementation"},{"location":"contribute/tomopackets/#sending-and-receiving-packets","text":"Each packet has a send(socket) function that allows it to be sent over any ZeroMQ socket. TomoPackets also has a built-in \u2018server\u2019. A tomop::server actually runs two independent \u2018servers\u2019: one for receiving projections, and one reconstruction server to respond to slice requests This is also where the descriptors come in: anything but packet_desc::set_slice, packet_desc::remove_slice, packet_desc::kill_scene are for example ignored by the \u2018reconstruction\u2019 server, while the projection server only listens to packet_desc::projection_data . You can use: set_slice_callback(callback_type callback) for adding custom reconstruction code and set_projection_callback(projection_callback_type callback) to handle new projections from the scanner. There is also a \u2018multiserver\u2019, which allows connections to more than one visualization tool (RECAST3D). It is also possible to make custom servers which is what SliceRecon and RECAST3D do: Make a ZeroMQ socket to receive messages Read the descriptor, and deserialize the message based on the descriptor. After this, handle the packet using its contents. Example code for custom server: socket_ . recv ( & update ); auto desc = (( tomop :: packet_desc * ) update . data ())[ 0 ]; switch ( desc ) { case tomop :: packet_desc :: scan_settings : { auto mbuffer = tomop :: memory_buffer ( update . size (), ( char * ) update . data ()); auto packet = std :: make_unique < tomop :: ScanSettingsPacket > (); packet -> deserialize ( std :: move ( mbuffer )); // ...","title":"Sending and receiving packets"},{"location":"contribute/tomopackets/#examples","text":"The communication between nodes happens in a using standardized network packets that contain data, commands, or parameters. Here we give some examples of these packets.","title":"Examples"},{"location":"contribute/tomopackets/#adapter-to-reconstructor","text":"The reconstructor needs to receive three types of information from the data adapter. Information about where the object is positioned in relation to the acquisition geometry. This is done using a tomop.geometry_specification_packet , which defines the minimum and maximum point of a bounding box around the object, which is the physical region to be reconstructed. Information of the acquisition geometry. This is done using either of the following four packets. tomop.parallel_beam_geometry_packet tomop.parallel_vec_geometry_packet tomop.cone_beam_geometry_packet tomop.cone_vec_geometry_packet The projection data. This is done using (multiple) tomop.projection_packet . The type field of his packet denotes dark ( 0 ), bright ( 1 ), or ordinary ( 2 ) projections.","title":"Adapter to Reconstructor"},{"location":"contribute/tomopackets/#reconstructor-tofrom-visualizer","text":"The communication between the reconstructor and visualizer uses the following packets. To construct a scene, a tomop.make_scene_packet is sent to the visualizer. This is done over a REQ/REP channel, the reply is the assigned scene_id which can be used to tag later packets. After the scene is constructed, the reconstructor waits to receive tomop.set_slice_packet requests. It responds to these packets using a tomop.slice_data_packet . If there are plugins active, this packet is sent to the first plugin in line, which sends it to the next plugin after it is done processing. The final plugin then sends it to the visualizer.","title":"Reconstructor to/from Visualizer"},{"location":"contribute/tomopackets/#other-uses","text":"Plugin system: make a server that reads a SliceDataPacket, modifies it and sends it along the pipeline. Only necessary change: slice data gets sent to plugin socket instead of RECAST, while plugin forwards it to RECAST Real-time alignment: e.g. send a control packet \u2018rotation_axis\u2019. This creates a slider in RECAST, and the reconstruction software gets notified when the user changes this. Can also be used for checkboxes (Gaussian pass, Paganin, \u2026), or drop down menus (changes FBP filter used, \u2026) Multi-GPU FBP/FDK reconstruction distribute ProjectionDataPackets round robin, and sum the resulting \u2018SliceDataPacket\u2019s at RECAST3D (using the member \u2018additive\u2019).","title":"Other uses"},{"location":"contribute/tomopackets/#conventions","text":"","title":"Conventions"},{"location":"contribute/tomopackets/#multi-dimensional-arrays","text":"Volume data is stored in x-y-z order (from major to minor). Projection data is stored in row-column order (from major to minor).","title":"Multi-dimensional arrays"},{"location":"contribute/tomopackets/#slice-orientation","text":"We need a convention for representing the orientation of a slice. The orientation is inside volume space and is completely independent from the number of pixels (i.e. the \u2018size\u2019 of an individual pixel is implied by the bounding square of a slice). We represent the orientation as 9 real numbers (a, b, \\ldots, i) (a, b, \\ldots, i) so that: \\begin{equation} \\begin{pmatrix} a & d & g \\\\ b & e & h \\\\ c & f & i \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_s \\\\ y_s \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x_w \\\\ y_w \\\\ z_w \\\\ 1 \\end{pmatrix} \\end{equation} \\begin{equation} \\begin{pmatrix} a & d & g \\\\ b & e & h \\\\ c & f & i \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_s \\\\ y_s \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} x_w \\\\ y_w \\\\ z_w \\\\ 1 \\end{pmatrix} \\end{equation} Where the vector \\vec{x}_s = (x_s, y_s) \\vec{x}_s = (x_s, y_s) lives inside a slice (i.e. the normalized pixel coordinates of a slice, in the interval [0, 1] [0, 1] ), and where \\vec{x}_w = (x_w, y_w, z_w) \\vec{x}_w = (x_w, y_w, z_w) lives inside the volume geometry at the correct place. The pixel coordinates of a slice have the following convention: \\begin{equation} \\begin{pmatrix} (0, m) & \\cdots & (n, m) \\\\ \\vdots & \\ddots & \\vdots \\\\ (0, 0) & \\cdots & (n, 0) \\end{pmatrix} \\end{equation} \\begin{equation} \\begin{pmatrix} (0, m) & \\cdots & (n, m) \\\\ \\vdots & \\ddots & \\vdots \\\\ (0, 0) & \\cdots & (n, 0) \\end{pmatrix} \\end{equation} i.e. we start counting from the bottom-left and use a standard cartesian xy xy convention. Using this convention, the vector \\vec{b} = (g, h, i) \\vec{b} = (g, h, i) is the base point of the slice in world space (i.e. the world coordinates of the bottom left point of a slice). \\vec{x} = (a,b,c) \\vec{x} = (a,b,c) is the direction in world space corresponding to the x x direction of the slice, and \\vec{y} = (d, e, f) \\vec{y} = (d, e, f) corresponds to the y y direction.","title":"Slice orientation"},{"location":"contribute/tomopackets/#acquisition-geometries","text":"The fields of the acquisition geometry packets: tomop.parallel_beam_geometry_packet tomop.parallel_vec_geometry_packet tomop.cone_beam_geometry_packet tomop.cone_vec_geometry_packet follow the conventions of the constructors of 3D Geometries of the ASTRA Toolbox. See http://www.astra-toolbox.com/docs/geom3d.html for an overview.","title":"Acquisition geometries"},{"location":"contribute/tomopackets/#usage","text":"","title":"Usage"},{"location":"contribute/tomopackets/#writing-a-reconstruction-node","text":"For writing a simple reconstructor that responds to slice reconstruction requests, you can use tomop.server and set a callback. You can also send other types of packets over the channel opened by this server. For example, sending a tomop.volume_data_packet enables a visualizer to show a 3D preview:: import tomop import numpy as np def callback ( orientation , slice_id ): print ( \"callback called\" ) print ( orientation ) return [ 4 , 4 ], np . array ([ 0 , 255 , 0 , 255 , 255 , 0 , 255 , 0 , 255 , 0 , 0 , 255 , 255 , 0 , 0 , 255 ], dtype = 'float32' ) serv = tomop . server ( \"scene name\" ) vdp = tomop . volume_data_packet ( serv . scene_id (), np . array ([ 2 , 2 , 2 ], dtype = 'int32' ) . tolist (), np . array ([ 0 , 255 , 128 , 255 , 255 , 128 , 255 , 0 ], dtype = 'float32' )) serv . send ( vdp ) serv . set_callback ( callback ) serv . serve ()","title":"Writing a reconstruction node"},{"location":"users/adapters/","text":"Writing an adapter Each scanner or data source, has different formats for storing projection data, specifying the (acquisition) geometry, and different requirements on data preprocessing. An adapter generates and sends three types of standardized packets from the specific scanner data: Scan settings : tomop.scan_settings_packet Geometry : geometry_specification_packet for the volume geometry, and e.g. tomop.parallel_beam_geometry_packet for the acquisition geometry. Projection data : tomop.projection_packet This gets sent (one way) to the projection server which is \u2018scanner agnostic\u2019. To support a different scanner (or microscope, beamline, dataset), you can write a straightforward data adapter in the form of simple Python script. Example adapters can be found in the examples directory of TomoPackets. To implement an adapter, we have to send the three types of packets to a listening reconstructor. To send these packets, we can use a tomop.publisher object. An example is provided below:: import tomop import numpy as np import argparse def push_zero_projections ( resolution , host = \"localhost\" , port = 5558 ): m = resolution proj_count , rows , cols = m , m , m scene_id = 0 pub = tomop . publisher ( host , port ) # We let the server know we will send one dark field, and one flat field num_darks , num_flats = 1 , 1 packet_scan_settings = tomop . scan_settings_packet ( scene_id , num_darks , num_flats , False ) pub . send ( packet_scan_settings ) # Initialize volume and acquisition geometry packet_vol_geom = tomop . geometry_specification_packet ( scene_id , [ 0 , 0 , 0 ], [ 1 , 1 , 1 ]) pub . send ( packet_vol_geom ) angles = np . linspace ( 0 , np . pi , proj_count , endpoint = False ) packet_geometry = tomop . parallel_beam_geometry_packet ( scene_id , rows , cols , proj_count , angles ) pub . send ( packet_geometry ) # Send dark(s) and flat(s) dark = np . zeros (( rows , cols ), dtype = np . float32 ) . ravel () packet_dark = tomop . projection_packet ( 0 , 0 , [ rows , cols ], dark ) pub . send ( packet_dark ) flat = np . ones (( rows , cols ), dtype = np . float32 ) . ravel () packet_flat = tomop . projection_packet ( 1 , 0 , [ rows , cols ], flat ) pub . send ( packet_flat ) # Create and send projection data consisting of zeros proj_data = np . zeros (( proj_count , rows , cols )) for i in np . arange ( 0 , proj_count ): packet_proj = tomop . projection_packet ( 2 , i , [ rows , cols ], proj_data [ i , :, :] . ravel ()) pub . send ( packet_proj ) if __name__ == '__main__' : parser = argparse . ArgumentParser ( description = 'Push a data set consisting of zeros to Slicerecon.' ) parser . add_argument ( '--host' , default = \"localhost\" , help = 'the projection server host' ) parser . add_argument ( '--port' , type = int , default = 5558 , help = 'the projection server port' ) parser . add_argument ( '--resolution' , type = int , default = 512 , help = 'the number of detector rows, detector columns, and angles' ) args = parser . parse_args () push_zero_projections ( args . resolution , host = args . host , port = args . port )","title":"Data adapters"},{"location":"users/adapters/#writing-an-adapter","text":"Each scanner or data source, has different formats for storing projection data, specifying the (acquisition) geometry, and different requirements on data preprocessing. An adapter generates and sends three types of standardized packets from the specific scanner data: Scan settings : tomop.scan_settings_packet Geometry : geometry_specification_packet for the volume geometry, and e.g. tomop.parallel_beam_geometry_packet for the acquisition geometry. Projection data : tomop.projection_packet This gets sent (one way) to the projection server which is \u2018scanner agnostic\u2019. To support a different scanner (or microscope, beamline, dataset), you can write a straightforward data adapter in the form of simple Python script. Example adapters can be found in the examples directory of TomoPackets. To implement an adapter, we have to send the three types of packets to a listening reconstructor. To send these packets, we can use a tomop.publisher object. An example is provided below:: import tomop import numpy as np import argparse def push_zero_projections ( resolution , host = \"localhost\" , port = 5558 ): m = resolution proj_count , rows , cols = m , m , m scene_id = 0 pub = tomop . publisher ( host , port ) # We let the server know we will send one dark field, and one flat field num_darks , num_flats = 1 , 1 packet_scan_settings = tomop . scan_settings_packet ( scene_id , num_darks , num_flats , False ) pub . send ( packet_scan_settings ) # Initialize volume and acquisition geometry packet_vol_geom = tomop . geometry_specification_packet ( scene_id , [ 0 , 0 , 0 ], [ 1 , 1 , 1 ]) pub . send ( packet_vol_geom ) angles = np . linspace ( 0 , np . pi , proj_count , endpoint = False ) packet_geometry = tomop . parallel_beam_geometry_packet ( scene_id , rows , cols , proj_count , angles ) pub . send ( packet_geometry ) # Send dark(s) and flat(s) dark = np . zeros (( rows , cols ), dtype = np . float32 ) . ravel () packet_dark = tomop . projection_packet ( 0 , 0 , [ rows , cols ], dark ) pub . send ( packet_dark ) flat = np . ones (( rows , cols ), dtype = np . float32 ) . ravel () packet_flat = tomop . projection_packet ( 1 , 0 , [ rows , cols ], flat ) pub . send ( packet_flat ) # Create and send projection data consisting of zeros proj_data = np . zeros (( proj_count , rows , cols )) for i in np . arange ( 0 , proj_count ): packet_proj = tomop . projection_packet ( 2 , i , [ rows , cols ], proj_data [ i , :, :] . ravel ()) pub . send ( packet_proj ) if __name__ == '__main__' : parser = argparse . ArgumentParser ( description = 'Push a data set consisting of zeros to Slicerecon.' ) parser . add_argument ( '--host' , default = \"localhost\" , help = 'the projection server host' ) parser . add_argument ( '--port' , type = int , default = 5558 , help = 'the projection server port' ) parser . add_argument ( '--resolution' , type = int , default = 512 , help = 'the number of detector rows, detector columns, and angles' ) args = parser . parse_args () push_zero_projections ( args . resolution , host = args . host , port = args . port )","title":"Writing an adapter"},{"location":"users/interface/","text":"User Interface Here we discuss the user interface of RECAST3D. We assume that there is a scene active, and that there is an active reconstruction server with non-zero projection data. Menu bar In the Scenes tab of the menu bar, all the current scenes are listed. Additional scenes can be added, or scenes can be deleted from this tab. Note that scenes are often created automatically, using an upstream server such as SliceRecon. Scene controls On the left, there is a window with controls for the scene. Color scheme A color scheme can be chosen with a picker interface. Fixed camera angles You can set the camera in the scene to fixed angles, for example by focusing on one of the three standard orthoslices. You can always reset the camera to the default position using the spacebar. Axes You can toggle the visibility of the axes indicator. In the axis indicator; red , green , and blue represent the x x , y y , and z z axis respectively. Contrast You can change the contrast in the scene using the min/max sliders at the bottom of the window. It also shows a histogram of the reconstruction data. Camera and slice controls Zooming You can zoom in, and out, using the scroll wheel on your mouse. Rotating the camera Rotating the camera around the object can be done by pressing the left mouse button while not hovering over a slice, and dragging the mouse. Changing a slice You can translate a slice by pressing the left mouse button while hovering over a slice, and dragging the mouse. This will translate the slice along its normal. Changing the orientation of a slice You can rotate a slice around one of its edges, by pressing the right mouse button while hovering over a slice. It will rotate around the furthest edge from where you click.","title":"Interface"},{"location":"users/interface/#user-interface","text":"Here we discuss the user interface of RECAST3D. We assume that there is a scene active, and that there is an active reconstruction server with non-zero projection data.","title":"User Interface"},{"location":"users/interface/#menu-bar","text":"In the Scenes tab of the menu bar, all the current scenes are listed. Additional scenes can be added, or scenes can be deleted from this tab. Note that scenes are often created automatically, using an upstream server such as SliceRecon.","title":"Menu bar"},{"location":"users/interface/#scene-controls","text":"On the left, there is a window with controls for the scene.","title":"Scene controls"},{"location":"users/interface/#color-scheme","text":"A color scheme can be chosen with a picker interface.","title":"Color scheme"},{"location":"users/interface/#fixed-camera-angles","text":"You can set the camera in the scene to fixed angles, for example by focusing on one of the three standard orthoslices. You can always reset the camera to the default position using the spacebar.","title":"Fixed camera angles"},{"location":"users/interface/#axes","text":"You can toggle the visibility of the axes indicator. In the axis indicator; red , green , and blue represent the x x , y y , and z z axis respectively.","title":"Axes"},{"location":"users/interface/#contrast","text":"You can change the contrast in the scene using the min/max sliders at the bottom of the window. It also shows a histogram of the reconstruction data.","title":"Contrast"},{"location":"users/interface/#camera-and-slice-controls","text":"","title":"Camera and slice controls"},{"location":"users/interface/#zooming","text":"You can zoom in, and out, using the scroll wheel on your mouse.","title":"Zooming"},{"location":"users/interface/#rotating-the-camera","text":"Rotating the camera around the object can be done by pressing the left mouse button while not hovering over a slice, and dragging the mouse.","title":"Rotating the camera"},{"location":"users/interface/#changing-a-slice","text":"You can translate a slice by pressing the left mouse button while hovering over a slice, and dragging the mouse. This will translate the slice along its normal.","title":"Changing a slice"},{"location":"users/interface/#changing-the-orientation-of-a-slice","text":"You can rotate a slice around one of its edges, by pressing the right mouse button while hovering over a slice. It will rotate around the furthest edge from where you click.","title":"Changing the orientation of a slice"},{"location":"users/live_scan/","text":"Running the stack Example : Reconstruction of a rat skull First, let us walk through a complete example before discussing each component in detail. Download skull.zip from doi:10.5281/zenodo.1164088 , and unzip it somewhere, say ~/data/skull . Install flexDATA, which is used in the data adapter we will use for this dataset. conda install -c cicwi -c astra-toolbox/label/dev -c conda-forge -c owlas flexdata Start up RECAST3D recast3d Start up a new scene slicerecon_server --slice-size 512 Stream the data into RECAST3D cd examples/adapters python flexdata_adapter.py ~/data/skull --sample 2 You should now see the dataset loaded into RECAST3D. Starting RECAST3D First, we have to start up RECAST3D. This either happens from the application launcher of your OS, or using a Linux terminal: # Inside a conda environment with RECAST3D installed conda activate [ your_environment ] recast3d # ... or inside the 'build' directory for a manual install cd recast3d/build ./recast3d Starting the SliceRecon reconstruction server After RECAST3D is running, we can start a reconstruction server. By default, we can run a SliceRecon server: cd slicerecon/build ./slicerecon_server [ options ] For example, with [options] we can set the slice resolution, preview resolution, and so on. For a full list of options, run with -h : ./slicerecon_server -h When a server is started, it connects with RECAST3D and tells it to create a new scene. After starting the server, the RECAST3D window should show a new scene with three inactive slices. Pushing data into the SliceRecon server using an adapter The server is now waiting until (projection) data is pushed to it. For example, we can push prerecorded data from the FleX-ray lab: cd examples/adapters python flexdata_adapter.py [ path ] (Optional) plugins To use or test (Python) plugins, we run the reconstruction server with --pyplugin . ./slicerecon_server --pyplugin [ other options ] and start our plugin: python plugin.py After the plugin is started, we can push data to SliceRecon using any adapter. To chain multiple plugins, simply change the outgoing host/port of a plugin to the incoming host/port of another. The final plugin should send the final processed slice data to RECAST3D using its host/port. Custom ports The setup above works if you use the default ports, and when all components are run on localhost . The default ports are as follows: 5555 : RECAST3D REQ/REP server 5556 : RECAST3D PUB/SUB server 5558 : SliceRecon server 5652 : Python based plugin These ports, as well as the host for RECAST3D or the (first) plugin, can be changed using flags to the SliceRecon server. One of the reasons for being aware of which ports to use, is for forwarding data between nodes. For example, if we have a host gpu_server that we want to use for running a slicerecon_server , but we want to visualize using RECAST3D on our workstation desktop , we can \u2018reverse tunnel\u2019 ports 5555 and 5556 when using SSH to access our box as follows: # on 'desktop' recast3d ssh gpu_server -R 5555 :localhost:5555 -R 5556 :localhost:5556 # ... now we are on 'gpu_server' slicerecon_server --slice-size 512 # ... this will connect to the RECAST3D instance running on 'desktop'","title":"Running the stack"},{"location":"users/live_scan/#running-the-stack","text":"","title":"Running the stack"},{"location":"users/live_scan/#example-reconstruction-of-a-rat-skull","text":"First, let us walk through a complete example before discussing each component in detail. Download skull.zip from doi:10.5281/zenodo.1164088 , and unzip it somewhere, say ~/data/skull . Install flexDATA, which is used in the data adapter we will use for this dataset. conda install -c cicwi -c astra-toolbox/label/dev -c conda-forge -c owlas flexdata Start up RECAST3D recast3d Start up a new scene slicerecon_server --slice-size 512 Stream the data into RECAST3D cd examples/adapters python flexdata_adapter.py ~/data/skull --sample 2 You should now see the dataset loaded into RECAST3D.","title":"Example: Reconstruction of a rat skull"},{"location":"users/live_scan/#starting-recast3d","text":"First, we have to start up RECAST3D. This either happens from the application launcher of your OS, or using a Linux terminal: # Inside a conda environment with RECAST3D installed conda activate [ your_environment ] recast3d # ... or inside the 'build' directory for a manual install cd recast3d/build ./recast3d","title":"Starting RECAST3D"},{"location":"users/live_scan/#starting-the-slicerecon-reconstruction-server","text":"After RECAST3D is running, we can start a reconstruction server. By default, we can run a SliceRecon server: cd slicerecon/build ./slicerecon_server [ options ] For example, with [options] we can set the slice resolution, preview resolution, and so on. For a full list of options, run with -h : ./slicerecon_server -h When a server is started, it connects with RECAST3D and tells it to create a new scene. After starting the server, the RECAST3D window should show a new scene with three inactive slices.","title":"Starting the SliceRecon reconstruction server"},{"location":"users/live_scan/#pushing-data-into-the-slicerecon-server-using-an-adapter","text":"The server is now waiting until (projection) data is pushed to it. For example, we can push prerecorded data from the FleX-ray lab: cd examples/adapters python flexdata_adapter.py [ path ]","title":"Pushing data into the SliceRecon server using an adapter"},{"location":"users/live_scan/#optional-plugins","text":"To use or test (Python) plugins, we run the reconstruction server with --pyplugin . ./slicerecon_server --pyplugin [ other options ] and start our plugin: python plugin.py After the plugin is started, we can push data to SliceRecon using any adapter. To chain multiple plugins, simply change the outgoing host/port of a plugin to the incoming host/port of another. The final plugin should send the final processed slice data to RECAST3D using its host/port.","title":"(Optional) plugins"},{"location":"users/live_scan/#custom-ports","text":"The setup above works if you use the default ports, and when all components are run on localhost . The default ports are as follows: 5555 : RECAST3D REQ/REP server 5556 : RECAST3D PUB/SUB server 5558 : SliceRecon server 5652 : Python based plugin These ports, as well as the host for RECAST3D or the (first) plugin, can be changed using flags to the SliceRecon server. One of the reasons for being aware of which ports to use, is for forwarding data between nodes. For example, if we have a host gpu_server that we want to use for running a slicerecon_server , but we want to visualize using RECAST3D on our workstation desktop , we can \u2018reverse tunnel\u2019 ports 5555 and 5556 when using SSH to access our box as follows: # on 'desktop' recast3d ssh gpu_server -R 5555 :localhost:5555 -R 5556 :localhost:5556 # ... now we are on 'gpu_server' slicerecon_server --slice-size 512 # ... this will connect to the RECAST3D instance running on 'desktop'","title":"Custom ports"},{"location":"users/plugins/","text":"Plugins Plugins can perform post-processing on reconstructed slices. Developing a plugin Developing a post-processing plugin is as easy as implementing a single Python function that takes a 2D numpy array (the reconstructed slice), and returns a 2D numpy array (the postprocessed slice). An example plugin looks like this. import numpy as np import slicerecon from skimage import filters def callback ( shape , xs , _ ): # The Otsu implementation does not accept only zeros, so we pass through if not np . array ( xs ) . any (): return [ shape , xs ] # Reshape into an image xs = np . array ( xs ) . reshape ( shape ) # Compute a threshold using Otsu's method val = filters . threshold_otsu ( xs ) # Threshold the image accordingly xs [ xs <= val ] = 0.0 xs [ xs > val ] = 1.0 return [ shape , xs . ravel () . tolist ()] # Host a plugin on the default port, with the default RECAST3D endpoint p = slicerecon . plugin ( \"tcp://*:5652\" , \"tcp://localhost:5555\" ) # Register the callback p . set_slice_callback ( callback ) # Start the plugin p . listen () This plugin listens to incoming SliceData packets on port 5652 , and connects to a visualization software (or another plugin) listening on port 5555 . These are the default values. If you use the standard slicerecon_server program, connecting the Python plugin is as easy as passing --pyplugin as a flag. This plugin computes a simple segmentation based on a threshold computed by Otsu\u2019s method . Testing your plugin Start RECAST3D: recast3d Start slicerecon_server , e.g.: slicerecon_server --slice-size 512 --pyplugin Run your plugin, e.g.: python plugin.py Stream projection data to the slicerecon_server , e.g.: python slicerecon_push_flexdata.py [ path_to_data ] --sample 2 If you make a change to plugin.py , you can restart it without touching the other components (recast3d, slicerecon) and without restreaming the projection data. Simply request a new reconstruction by modifying a slice (e.g. by clicking on one of the slices in RECAST3D) to see the result. Example : Otsu thresholding The example above should give the following visual result. Dataset: A cone beam scan of a rat skull : doi:10.5281/zenodo.1164088","title":"Plugins"},{"location":"users/plugins/#plugins","text":"Plugins can perform post-processing on reconstructed slices.","title":"Plugins"},{"location":"users/plugins/#developing-a-plugin","text":"Developing a post-processing plugin is as easy as implementing a single Python function that takes a 2D numpy array (the reconstructed slice), and returns a 2D numpy array (the postprocessed slice). An example plugin looks like this. import numpy as np import slicerecon from skimage import filters def callback ( shape , xs , _ ): # The Otsu implementation does not accept only zeros, so we pass through if not np . array ( xs ) . any (): return [ shape , xs ] # Reshape into an image xs = np . array ( xs ) . reshape ( shape ) # Compute a threshold using Otsu's method val = filters . threshold_otsu ( xs ) # Threshold the image accordingly xs [ xs <= val ] = 0.0 xs [ xs > val ] = 1.0 return [ shape , xs . ravel () . tolist ()] # Host a plugin on the default port, with the default RECAST3D endpoint p = slicerecon . plugin ( \"tcp://*:5652\" , \"tcp://localhost:5555\" ) # Register the callback p . set_slice_callback ( callback ) # Start the plugin p . listen () This plugin listens to incoming SliceData packets on port 5652 , and connects to a visualization software (or another plugin) listening on port 5555 . These are the default values. If you use the standard slicerecon_server program, connecting the Python plugin is as easy as passing --pyplugin as a flag. This plugin computes a simple segmentation based on a threshold computed by Otsu\u2019s method .","title":"Developing a plugin"},{"location":"users/plugins/#testing-your-plugin","text":"Start RECAST3D: recast3d Start slicerecon_server , e.g.: slicerecon_server --slice-size 512 --pyplugin Run your plugin, e.g.: python plugin.py Stream projection data to the slicerecon_server , e.g.: python slicerecon_push_flexdata.py [ path_to_data ] --sample 2 If you make a change to plugin.py , you can restart it without touching the other components (recast3d, slicerecon) and without restreaming the projection data. Simply request a new reconstruction by modifying a slice (e.g. by clicking on one of the slices in RECAST3D) to see the result.","title":"Testing your plugin"},{"location":"users/plugins/#example-otsu-thresholding","text":"The example above should give the following visual result. Dataset: A cone beam scan of a rat skull : doi:10.5281/zenodo.1164088","title":"Example: Otsu thresholding"}]}